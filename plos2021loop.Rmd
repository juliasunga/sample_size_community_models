---
title: "plos20201loop"
author: "Julia Sunga"
date: "14/04/2021"
output: pdf_document
---
The following code is used once the "observed" network has been created and established by selecting your full set of observations from your master dataset or by using truenetwork.csv from Dryad 

For each number of individuals and number of observations per individual combination, set the loop to run for the desired number of replicates. Output values will be stored in your created matrices for each metric. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

truest<-read.csv("truenetwork.csv")

library(assortnet)
library(igraph)
library(asnipe)
library(spatsoc)
library(dplyr)
library(tidyr)
library(data.table)
library(reshape2)
library(tibble)

truest2<-as.data.table(truest)
#read in truematrix groups list
observedgroups<-read.csv("observedgroups.csv")
observedgroups<-as.data.table(observedgroups)


#create table to store results - recreate before each run to ensure table only contains the specified sampling regime

Qact<-matrix()
p<-matrix()
groups<-matrix()
rc<-matrix()
den<-matrix()
dia<-matrix()
cen<-matrix()
bet<-matrix()
cc<-matrix()
sim<-matrix()

#loops to run 

for (i in 1:100) {
  
  counteach<-count(truest2, pit)
  #change to indicate number of individuals to pull
  inds<-counteach[sample(nrow(counteach), 50, replace=F),]
  indsample<-truest2[truest2$pit %in% inds$pit]
  
  #subset observations per individual
  by_pit <- indsample %>% group_by(pit)
  
  #change to indicate number of observations per individual to pull
  mysubset<-sample_n(by_pit, 20)
  
  
  
  #### FOR each of the above parameters run to get Q (# of subgroups) and Rc (just to see what it looks like
  
  #merge box and pitymd to get daygroup
  mysubset$daygroup<-paste(mysubset$box, "-", mysubset$pitymd)
  
  #check correct number have been selected
  unique(mysubset$pit)
  mysubset<-as.data.table(mysubset)
  
  ####Q Code
  individuals <- mysubset[,.(ID = pit, group = daygroup, day = pitymd)]
  sampleGBI <- get_group_by_individual(individuals, data_format = "individuals")
  
  #bootstrap new networks avoiding network_permutation function - SET # OF ITERATIONS HERE
  mysubset[, pitymd := as.POSIXct(pitymd)]
  
  
  mysubset$box1 <- as.numeric(mysubset$box)
  mysubset$box2 <- as.numeric(mysubset$box)
  group_pts(mysubset, threshold = 1, id = 'pit', coords = c('box1', 'box2'),
            timegroup = 'pitymd')
  
  N = 1000
  rand <- randomizations(mysubset, type = 'daily', coords = NULL,
                         id = 'pit', group = 'group', 
                         datetime = 'pitymd', iterations = N)
  ## Create a data.table of unique combinations of iteration, year exluding observed rows
  iterLocLs <- unique(rand[!(observed), .(iteration)])
  
  ## Generate group by individual matrix 
  # for each combination of iteration number and year
  # 'group' generated by spatsoc::group_pts
  # 'randomID' used instead of observed ID (type = 'step')
  gbiLs <- mapply(
    FUN = function(i) {
      get_gbi(rand[iteration == i ],
              'group', 'randomID')
    },
    i = iterLocLs$iter,
    
    SIMPLIFY = FALSE
  )
  
  ## Generate a list of random networks
  ## 
  netLs <- lapply(gbiLs, FUN = get_network,
                  data_format = "GBI", association_index = "HWI")
  
  
  ## Generate graph and calculate network metrics
  mets <- lapply(seq_along(netLs), function(n) {
    g <- graph.adjacency(netLs[[n]], 'undirected', 
                         diag = FALSE, weighted = TRUE)
    
    data.table(
      Q = modularity(cluster_fast_greedy(g)),
      iteration = iterLocLs$iter[[n]]
    )
  })
  
  ## generate data.table from list output 
  randomvalues<-rbindlist(mets)
  
  
  
  
  #add actual Q to whichever year from above
  #get subset from network subset code
  
  individuals <- data.frame(ID=c(mysubset$pit),group=c(mysubset$daygroup),day=c(mysubset$pitymd))
  sampleGBI <- get_group_by_individual(individuals, data_format = "individuals")
  net_matrix <- get_network(sampleGBI,data_format="GBI",association_index="HWI")
  graph_object <- graph.adjacency(net_matrix,mode="undirected",diag=FALSE,weighted=TRUE)
  
  Qact<-rbind(Qact, modularity(cluster_fast_greedy(graph_object)))
  Qcurrent<-modularity(cluster_fast_greedy(graph_object))
  x<-sum(randomvalues$Q > Qcurrent)
  p<-rbind(p, x/length(randomvalues$Q))
  p
  
  ####Rcom code - from Shizuka and Farine 2016
  #create table to store results
  network.community <- matrix(0,ncol(sampleGBI),ncol(sampleGBI))
  network.present <- matrix(0,ncol(sampleGBI),ncol(sampleGBI))
  
  # 1. Calculate network
  network <- get_network(sampleGBI, data_format="GBI", association_index="HWI")
  
  # 2. Calculate community membership of the observed network
  community.observed <- fastgreedy.community(graph.adjacency(network, mode="undirected",weighted=TRUE))
  
  #bootstrap new networks avoiding network_permutation function - SET # OF ITERATIONS HERE
  for (i in 1:1000) {
    gbi.boot <- sampleGBI[sample(1:nrow(sampleGBI),nrow(sampleGBI),replace=TRUE),]
    network.boot <- get_network(gbi.boot,data_format="GBI", association_index="HWI")
    
    # This step calculates the community membership from the bootstrapped network
    community.boot <- fastgreedy.community(graph.adjacency(network.boot,mode="undirected",weighted=TRUE))
    
    # This step adds 1 to any dyads in the same community
    network.community <- network.community + outer(community.boot$membership, community.boot$membership,"==")
    
    
    # This step adds 1 to any dyads that are both present (in this case if they have at least 1 edge)
    network.present <- network.present + outer((rowSums(network.boot)>0),(rowSums(network.boot)>0),"*")
  } 
  #end boot strap	
  
  # Calculate proportion of times observed in the same community
  P <- network.community/network.present
  P[!is.finite(P)] <- 0
  
  # Calculate assortment from known community membership
  rc <- rbind(rc, assortment.discrete(P,community.observed$membership)$r)
  
  #calculate number of detected groups
  groups<-rbind(groups, length(unique(membership(community.observed))))
  
  #calculate network density - igraph edge_density
  den<-rbind(den, edge_density(graph_object, loops=FALSE))
  
  #calculate network diameter
  dia<-rbind(dia, diameter(graph_object, unconnected=FALSE, weights=NA))
  
  #calculate clustering coefficient (transitivity)
  cc<-rbind(cc, transitivity(graph_object, type="globalundirected", weights=NULL, isolates="zero"))
  
  #calculate betweenness centrality
  
  bet<-rbind(bet,centr_betw(graph_object, directed=FALSE, nobigint=TRUE, normalized=TRUE)$centralization)
  #calculate degree centrality
  
  cen<-rbind(cen,centr_degree(graph_object, loops=TRUE, normalized=TRUE)$centralization) 

  #calculate the correlation in individual group assignment
  ### create list of individuals and associated groups 
  groupslist<-as.list(membership(community.observed))
  groups2<-as.data.frame(groupslist, check.names=FALSE) %>% t() %>% as.data.frame() %>% rownames_to_column(var="id")
  groups2$groups<-groups2$V1
  groups2$id<-as.character(groups2$id)
  groups3<-as.data.table(groups2)
  
  ###create similar list from observed network for all those that appear in above
  observedsubset<-observedgroups[observedgroups$id %in% groups3$id]
  
  ###convert each to individualxindividual matrix of shared group membership
  
  #creates a list of all possible comparisons
  compare<-as.data.frame(t(combn(observedsubset$id, 2)))
 
  observedsubset$id<-as.character(observedsubset$id)
  
  #use leftjoin to get group #s for each individual in each comparison
 newtable<-left_join(compare, observedsubset, by=c("V1"="id"))
 newtable2<-as.data.table(left_join(newtable, observedsubset, by=c("V2"="id")))
 #ifelse statement to compare groups.x to groups.y
 newtable2$samegroup<-as.numeric(ifelse(newtable2$groups.x==newtable2$groups.y, "1", "0"))
 #convert to matrix
  observedmatrix<-acast(newtable2, V1.x~V2)
 
  #repeat for the subset data and those assignments
  compare2<-as.data.frame(compare)
  newtable3<-left_join(compare2, groups3, by=c("V1"="id"))
  newtable4<-left_join(newtable3, groups3, by=c("V2"="id"))
  newtable4$samegroup<-as.numeric(ifelse(newtable4$groups.x==newtable4$groups.y, "1", "0"))
  
  currentmatrix<-acast(newtable4, V1.x~V2)
  
  #want % of correctly assigned dyads
  newmatrix<-as.matrix(ifelse(currentmatrix==observedmatrix, 1, 0))
  
  NAs<-sum(is.na(newmatrix))
  newmatrix[is.na(newmatrix)]<-0
  #double sum and divide by number of cells
  sim<-rbind(sim, sum(newmatrix)/(length(newmatrix)-NAs))
    }

result<-cbind(Qact, p, rc, groups, den, dia, cc, bet, cen, sim)

 write.csv(result, file="temporary.csv")
```

After each sampling regime is tested (set number of observations and number of individuals), output is manually copied into an external .csv file to compile all sampling regimes together, generating the file 'networktestnew.csv' which will be read into "plos2021analysisandfigures.Rmd". Note that not all calculated values are used in the manuscript. 

